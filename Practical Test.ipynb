{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50788eda-154a-4012-a4ce-fe8c8c6355bc",
   "metadata": {},
   "source": [
    "# Setup MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee589e7e-86b8-4f83-8d47-a0258cc75ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client.healthcare_supply_chain\n",
    "products = db.products\n",
    "events = db.events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772c678-8d68-47a9-82c8-da541797d9c2",
   "metadata": {},
   "source": [
    "# Ingest CSV and Json to MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fc9f48-0f69-410c-9454-a8254bd728b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def process_batch(batch, header, collection):\n",
    "    \"\"\"\n",
    "    Process a batch of rows.\n",
    "    convert a row in dicitonary to put it in Mongodb\n",
    "    \"\"\"\n",
    "    for row in batch:\n",
    "        # Example: Print each row\n",
    "        doc = dict(map(lambda i: (header[i], row[i]), range(len(header)-1)))\n",
    "        try:\n",
    "            db[collection].insert_one(doc)\n",
    "        except pymongo.errors.DuplicateKeyError:\n",
    "            print(\"Key :\" + doc[\"_id\"] + \" alredy in collection\")\n",
    "\n",
    "def ingest_csv(filename, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Ingest a CSV file in batches. So we can't run out of memory\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        header = next(csv_reader)  # Read the header row\n",
    "        header[0] = '_id'\n",
    "        batch = []\n",
    "        for row in csv_reader:\n",
    "            batch.append(row)\n",
    "            if len(batch) >= batch_size:\n",
    "                process_batch(batch, header, \"products\")\n",
    "                batch = []\n",
    "        # Process the remaining rows (if any)\n",
    "        \n",
    "        if batch:\n",
    "            process_batch(batch, header, \"products\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"Healthcare_Supply_Chain_Products.csv\" \n",
    "    ingest_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85de0f6b-ea4b-458c-ae09-1f28fd8c4685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9755bbb6-0c30-47ff-980f-3089d6c603b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'P10000',\n",
       " 'Product Name': 'Product 0',\n",
       " 'Category': 'Personal Protective Equipment',\n",
       " 'Supplier ID': 'S400'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cef1480-7f19-4f0b-a562-e22ef759efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_batch(batch, collection):\n",
    "    \"\"\"\n",
    "    Process a batch of rows.\n",
    "    convert a row in dicitonary to put it in Mongodb\n",
    "    \"\"\"\n",
    "    for item in batch:\n",
    "        item[\"_id\"] = item.pop(\"Event ID\")\n",
    "        try:\n",
    "            db[collection].insert_one(item)\n",
    "        except pymongo.errors.DuplicateKeyError:\n",
    "            print(\"Key :\" + item[\"_id\"] + \" alredy in collection\")\n",
    "\n",
    "def ingest_json(filename, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Ingest a json file in batches. So we can't run out of memory\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        batch = []\n",
    "        for line in file:\n",
    "            # Parse the JSON line one by one\n",
    "            batch.append(json.loads(line))\n",
    "            if len(batch) >= batch_size:\n",
    "                process_batch(batch, \"events\")\n",
    "                batch = []\n",
    "        if batch:  # pour gérer le cas où le dernier lot est inférieur à batch_size\n",
    "            process_batch(batch, \"events\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"Healthcare_Supply_Chain_Events.json\"\n",
    "    ingest_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5448c2e3-605c-42bd-8459-74ee670038bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f8ed9a41-9565-4477-8457-929c7aeec1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'E50000',\n",
       " 'Product ID': 'P10018',\n",
       " 'Timestamp': 1713235746125,\n",
       " 'Location': 'L102',\n",
       " 'Quantity': 44,\n",
       " 'Status': 'Shipped'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.find_one()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77dd3377-ece7-4cd6-8120-78ab2c83e35b",
   "metadata": {},
   "source": [
    "# Clean and Validate documents in database\n",
    "Data are already indexed over there ID\n",
    "\n",
    "We can add index to improve aggregates/sorting functions\n",
    "\n",
    "New indexes : \n",
    "- Products\n",
    "    - Category\n",
    "    - Supplier ID\n",
    "- Events\n",
    "    - timestamp & location\n",
    "    - status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73520f78-92c8-4967-8e1c-385fc95dc5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'status_1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.products.create_index([\"Category\"], unique=False)\n",
    "db.products.create_index([\"Supplier ID\"], unique=False)\n",
    "db.events.create_index([(\"timestamp\", pymongo.ASCENDING),\n",
    "                       (\"location\")], unique=False)\n",
    "db.events.create_index([\"status\"], unique=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec20cc-5694-4a57-a430-66ffdbd8b5f9",
   "metadata": {},
   "source": [
    "# Creating a table\n",
    "\n",
    "Amount of product ordered in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "136762ed-7d7f-4c2b-bc8d-7dd563f57bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "daily_totals_collection = db['daily_totals']\n",
    "\n",
    "pipeline = [\n",
    "        {\n",
    "            \"$match\": {\"Status\": \"Ordered\"}\n",
    "        },\n",
    "        {\n",
    "            \"$lookup\": {\n",
    "                \"from\": \"products\",\n",
    "                \"localField\": \"Product ID\",\n",
    "                \"foreignField\": \"_id\",\n",
    "                \"as\": \"product\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$unwind\": \"$product\"\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"date\": {\"$dateToString\": {\"format\": \"%Y-%m-%d\", \"date\": {\"$toDate\": {\"$multiply\": [\"$Timestamp\", 1]}}}},\n",
    "                \"Product Name\": \"$product.Product Name\",\n",
    "                \"Quantity\": \"$Quantity\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": {\"date\": \"$date\", \"Product Name\": \"$Product Name\"},\n",
    "                \"total_amount\": {\"$sum\": \"$Quantity\"}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "results = events.aggregate(pipeline)\n",
    "\n",
    "# Insert daily totals into the new collection\n",
    "for result in results:\n",
    "    daily_totals_collection.insert_one({\n",
    "        \"date\": result['_id']['date'],\n",
    "        \"Product Name\": result['_id']['Product Name'],\n",
    "        \"total_amount\": result['total_amount']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "310f9dcb-4217-4f86-8314-aba61669fa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('66270c39434585a54a35b2d7'),\n",
       " 'date': '2024-04-16',\n",
       " 'Product Name': 'Product 41',\n",
       " 'total_amount': 117}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_totals_collection.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12837b2-adfc-42c5-bdd1-b16b2c53f9f1",
   "metadata": {},
   "source": [
    "So there is 117 product 41 ordered on the 2024-04-16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
